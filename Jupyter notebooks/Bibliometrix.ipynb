{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# **Bibliometrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Prerequisites and Documentation**  \n",
    "- Install R\n",
    "- Install R kernel in Jupyter Lab (I used the instructions from here https://richpauloo.github.io/2018-05-16-Installing-the-R-kernel-in-Jupyter-Lab/)  \n",
    "  Find the location of the file R.exe on your computer (C\\Program Files\\R\\R-3.4.3\\bin), open Anaconda prompt, move to the folder (cd C:\\Program Files\\R\\R-3.4.3\\bin) and type \"R.exe\" to open it. Then type \"install.packages(\"devtools\")\". Then download and install Git for windows from the web (this step is different in the webpage, but it worked for me this way, probably because of windows). Then finally type \"IRkernel::installspec()\"  \n",
    "\n",
    "### **Important Information**\n",
    "\n",
    "**FIELD TAGS of Web Of Science core collection**\n",
    "http://www.bibliometrix.org/documents/Field_Tags_bibliometrix.pdf  \n",
    "**Main manual (for function references)**\n",
    "https://cran.r-project.org/web/packages/bibliometrix/bibliometrix.pdf  \n",
    "**Examples and explanations manual**\n",
    "https://cran.r-project.org/web/packages/bibliometrix/vignettes/bibliometrix-vignette.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## **Library execution and file reading** \n",
    "First we execute the bibliometrix library package and convert the BibTeX files downloaded from Scopus and WOS into dataframes on R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(bibliometrix)\n",
    "library(ggplot2)\n",
    "library(reshape2)\n",
    "# options(jupyter.plot_mimetypes = c(\"text/plain\", \"image/png\" ))\n",
    "setwd(\"/Users/macadmin/Google Drive/Shared Folders/GW-ABM — Review/Bibliometric Analysis/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **I - New Database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we set up the working directory (wd)\n",
    "setwd(\"/Users/macadmin/Google Drive/GW-ABM — Review/Bibliometric Analysis/\")\n",
    "\n",
    "# We read databases from WOS and Scopus (BibTeX files in wd) \n",
    "SDB <- readFiles(\"Data/Floods/Floods_SCOPUS.bib\")\n",
    "WDB <- readFiles(\"Data/Floods/Floods_WOS1.bib\")\n",
    "WDB2 <- readFiles(\"Data/Floods/Floods_WOS2.bib\")\n",
    "\n",
    "# Converting BibTeX to Dataframes\n",
    "SDB_DF <- convert2df(SDB, dbsource = \"scopus\", format = \"bibtex\")\n",
    "WDB_DF <- convert2df(WDB, dbsource = \"isi\", format = \"bibtex\")\n",
    "WDB_DF_2 <- convert2df(WDB2, dbsource = \"isi\", format = \"bibtex\")\n",
    "\n",
    "\n",
    "# We merge dataframes and remove duplicates\n",
    "#Merged <- mergeDbSources(WDB_DF, SDB_DF, remove.duplicated=TRUE)\n",
    "Merged <- mergeDbSources(WDB_DF, SDB_DF, WDB_DF_2,remove.duplicated=TRUE)\n",
    "\n",
    "# We remove duplicates by searching through the title field (then we use the DOI identifier in python, since NaN values could be dropped in R)\n",
    "New_Merged <- duplicatedMatching(Merged, Field = \"TI\", tol = 0.90)\n",
    "message(nrow(New_Merged), ' rows and ', ncol(New_Merged), ' columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Document Types Cleanup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Here we erase rows in which column DT equals \"BOOK\"\n",
    "M <- New_Merged[New_Merged$DT != \"BOOK\", ]\n",
    "message(nrow(M), ' rows and ', ncol(M), ' columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metatags incertion to Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M <- New_Merged\n",
    "# Here we chek the cited references [CR] column, obtaining a \";\" separator\n",
    "#message(M$CR[1])  \n",
    "message(nrow(M), ' rows and ', ncol(M), ' columns')\n",
    "\n",
    "# This code retrieves FIELD TAGS (e.g. references authors) not included in the dataframe generated but still in the database and adds them as new columns\n",
    "M <- metaTagExtraction(M, Field = \"CR_AU\", sep = \";\")   # First author of each cited reference\n",
    "M <- metaTagExtraction(M, Field = \"CR_SO\", sep = \";\")   # Source of each cited reference\n",
    "M <- metaTagExtraction(M, Field = \"AU_CO\", sep = \";\")   # Country of affiliation for each co-author\n",
    "M <- metaTagExtraction(M, Field = \"AU1_CO\", sep = \";\")  # Country of affiliation for the first author\n",
    "M <- metaTagExtraction(M, Field = \"AU_UN\", sep = \";\")   # University of affiliation  for each co-author and the corresponding author\n",
    "M <- metaTagExtraction(M, Field = \"SR\", sep = \";\")      # Short tag of the document\n",
    "message(nrow(M), ' rows and ', ncol(M), ' columns')\n",
    "\n",
    "# Finally we create a .csv file for further cleaning of the database through Python\n",
    "write.csv(M,'Merged_Dataframe_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **I.I - Database cleaning through Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **I.II - Reupdate of database to Bibliometrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here after reading we set the proper conditions of each column, be aware there might be less column tags.\n",
    "M <- read.csv(file = \"Database.csv\") # Or: \"Merged_Dataframe_2_checked.csv\"\n",
    "M$DE<- as.character(M$DE)\n",
    "M$SO<- as.character(M$SO)\n",
    "M$AU_UN<- as.character(M$AU_UN)\n",
    "M$AU_CO<- as.character(M$AU_CO)\n",
    "M$AU<- as.character(M$AU)\n",
    "M$AU1_CO<- as.character(M$AU1_CO)\n",
    "M$AU_UN<- as.character(M$AU_UN)\n",
    "M$AU_UN_NR<- as.logical(M$AU_UN_NR)\n",
    "M$AU1_UN<- as.character(M$AU1_UN)\n",
    "M$CR_AU<- as.character(M$CR_AU)\n",
    "M$CR_SO<- as.character(M$CR_SO)\n",
    "M$DT<- as.character(M$DT)\n",
    "M$DT2<- as.character(M$DT2)\n",
    "M$ID<- as.character(M$ID)\n",
    "M$JI<- as.character(M$JI)\n",
    "M$LA<- as.character(M$LA)\n",
    "M$PN<- as.character(M$PN)\n",
    "M$PP<- as.character(M$PP)\n",
    "M$PU<- as.character(M$PU)\n",
    "M$PY<- as.numeric(M$PY)\n",
    "M$RP<- as.character(M$RP)\n",
    "M$SN<- as.character(M$SN)\n",
    "M$AB<- as.character(M$AB)\n",
    "M$DB<- as.character(M$DB)\n",
    "M$CR<- as.character(M$CR)\n",
    "M$SR<- as.character(M$SR)\n",
    "M$AR<- as.character(M$AR)\n",
    "M$C1<- as.character(M$C1)\n",
    "M$DI<- as.character(M$DI)\n",
    "M$SR_FULL<- as.character(M$SR_FULL)\n",
    "M$TC<- as.numeric(M$TC)\n",
    "M$TI<- as.character(M$TI)\n",
    "M$VL<- as.character(M$VL)\n",
    "\n",
    "M$FU<- as.character(M$FU)\n",
    "M$BN<- as.character(M$BN)\n",
    "message('Database has ', nrow(M), ' rows and ', ncol(M), ' columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-indexing, only if needed\n",
    "M <- subset(M, select = -c(X) )\n",
    "rownames(M) <- M$Unnamed..0\n",
    "M <- subset(M, select = -c(Unnamed..0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **II - Updating (previous) Database with new papers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add new papers to the database: First, we read the input bibtex file. Then, export it as a csv with al its columns. Finally, it is concatenated to the actual database in csv and read back to bibliometrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read databases from WOS and/or Scopus (BibTeX files in wd) \n",
    "#WDB_new <- readFiles(\"Data/wos.bib\")\n",
    "SDB_new <- readFiles(\"Data/scopus_new_DB.bib\")\n",
    "\n",
    "# Converting BibTeX to Dataframes\n",
    "#WDB_DF <- convert2df(WDB_new, dbsource = \"isi\", format = \"bibtex\")\n",
    "SDB_DF <- convert2df(SDB_new, dbsource = \"scopus\", format = \"bibtex\")\n",
    "\n",
    "# N <- WDB_DF\n",
    "N <- SDB_DF\n",
    "\n",
    "message('New database has ',nrow(N), ' rows and ', ncol(N), ' columns')\n",
    "message('Old database has ', nrow(M), ' rows and ', ncol(M), ' columns')\n",
    "Merged <- mergeDbSources(M, N)\n",
    "message('Merged database now has ', nrow(Merged), ' rows and ', ncol(Merged), ' columns')\n",
    "\n",
    "\n",
    "Merged <- metaTagExtraction(Merged, Field = \"CR_AU\", sep = \";\")   # First author of each cited reference\n",
    "Merged <- metaTagExtraction(Merged, Field = \"CR_SO\", sep = \";\")   # Source of each cited reference\n",
    "Merged <- metaTagExtraction(Merged, Field = \"AU_CO\", sep = \";\")   # Country of affiliation for each co-author\n",
    "Merged <- metaTagExtraction(Merged, Field = \"AU1_CO\", sep = \";\")  # Country of affiliation for the first author\n",
    "Merged <- metaTagExtraction(Merged, Field = \"AU_UN\", sep = \";\")   # University of affiliation  for each co-author and the corresponding author\n",
    "Merged <- metaTagExtraction(Merged, Field = \"SR\", sep = \";\")      # Short tag of the document\n",
    "message('Merged database now has ', nrow(Merged), ' rows and ', ncol(Merged), ' columns')\n",
    "\n",
    "write.csv(Merged,'Updated_Database.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **II.I - Database cleaning through Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **II.II - Reupdate of database to Bibliometrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here after reading we set the proper conditions of each column, be aware there might be less column tags.\n",
    "M <- read.csv(file = \"FL_ABM_DB.csv\")\n",
    "M$DE<- as.character(M$DE)\n",
    "M$SO<- as.character(M$SO)\n",
    "M$AU_UN<- as.character(M$AU_UN)\n",
    "M$AU_CO<- as.character(M$AU_CO)\n",
    "M$AU<- as.character(M$AU)\n",
    "M$AU1_CO<- as.character(M$AU1_CO)\n",
    "M$AU_UN<- as.character(M$AU_UN)\n",
    "M$AU_UN_NR<- as.logical(M$AU_UN_NR)\n",
    "M$AU1_UN<- as.character(M$AU1_UN)\n",
    "M$CR_AU<- as.character(M$CR_AU)\n",
    "M$CR_SO<- as.character(M$CR_SO)\n",
    "M$DT<- as.character(M$DT)\n",
    "M$DT2<- as.character(M$DT2)\n",
    "M$ID<- as.character(M$ID)\n",
    "M$JI<- as.character(M$JI)\n",
    "M$LA<- as.character(M$LA)\n",
    "M$PN<- as.character(M$PN)\n",
    "M$PP<- as.character(M$PP)\n",
    "#M$PU<- as.character(M$PU)\n",
    "M$PY<- as.numeric(M$PY)\n",
    "M$RP<- as.character(M$RP)\n",
    "M$SN<- as.character(M$SN)\n",
    "M$AB<- as.character(M$AB)\n",
    "M$DB<- as.character(M$DB)\n",
    "M$CR<- as.character(M$CR)\n",
    "M$SR<- as.character(M$SR)\n",
    "M$AR<- as.character(M$AR)\n",
    "M$C1<- as.character(M$C1)\n",
    "M$DI<- as.character(M$DI)\n",
    "M$SR_FULL<- as.character(M$SR_FULL)\n",
    "M$TC<- as.numeric(M$TC)\n",
    "M$TI<- as.character(M$TI)\n",
    "M$VL<- as.character(M$VL)\n",
    "\n",
    "#M$FU<- as.character(M$FU)\n",
    "#M$BN<- as.character(M$BN)\n",
    "message('Database has ', nrow(M), ' rows and ', ncol(M), ' columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## **III - Outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Descriptive Summary**  \n",
    "Here we create a summary of the bibliographic data through several output tables and graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The variable \"results\" saves the bibliographic summary (here \"k\" indicates how many rows will be printed in each table)\n",
    "results <- biblioAnalysis(M, sep = \";\")     \n",
    "options(width=100)\n",
    "S <- summary(object = results, k = 20, pause = FALSE)\n",
    "plot(x = results, k = 20, pause = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Sankey Plot - Three Fields Plot**\n",
    "This diagram allows to visualize the main items of three fields (e.g. authors, keywords, journals), and how they are related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here \"n\" indicates the number of items to plot in each field, and width and height are in pixels\n",
    "threeFieldsPlot(M, fields = c(\"SO\", \"DE\", \"AU1_CO\"), n = c(20, 20, 20), width = 1000, height = 900)   # Authors - Author Keywords - Sources (Journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here \"n\" indicates the number of items to plot in each field, and width and height are in pixels\n",
    "threeFieldsPlot(M, fields = c(\"AU\", \"DE\", \"SO\"), n = c(10, 11, 11), width = 1000, height = 900)   # Authors - Author Keywords - Sources (Journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here \"n\" indicates the number of items to plot in each field, and width and height are in pixels\n",
    "threeFieldsPlot(M, fields = c(\"AU\", \"DE\", \"SO\"), n = c(8, 11, 5), width = 1000, height = 900)   # Authors - Author Keywords - Sources (Journal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### **3. Bibliographic Networks**  \n",
    "Different bibliographic Networks (matrixes) can be built, considering \"authors\" (AU), \"references\" (CR_SO), \"sources\" (SO), \"countries\" (AU_CO + AU1_CO), \"keywords\" (ID), \"author_keywords\" (DE), \"titles\" (TI), or \"abstracts\" (AB). Outputs include main statistics and plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NetworkPlot Function**  \n",
    "- Normalize: The association strength or proximity index. The inclusion index, also called Simpson coefficient, is an overlap measure used in information retrieval. The Jaccard index (or Jaccard similarity coefficient) gives us a relative measure of the overlap of two sets. It is calculated as the ratio between the intersection and the union of the reference lists (of two manuscripts). The Salton index, instead, relates the intersection of the two lists to the geometric mean of the size of both sets. The square of Salton index is also called Equivalence index. The indices are equal to zero if the intersection of the reference lists is empty.\n",
    "\n",
    "\n",
    "- Weighted:  This argument specifies whether to create a weighted graph from an adjacency matrix.   If it is NULL then an unweighted graph is created and the elements of the adjacency matrix gives the number of edges between the vertices.  If it is a character constant then for every non-zero matrix entry an edge is created and the value of the entry is added as an edge attribute named by the weighted argument.  If it is TRUE then a weighted graph is created and the name of the edge attribute will be weight.\n",
    "\n",
    "| Function Parameter |   Possibilities   |    Definition    |\n",
    "|:--------------------:|:-------------------:|:------------------:|\n",
    "|*1- Methods*|\n",
    "|   **Normalize**    | \"Association\", \"Jaccard\", \"Inclusion\", \"Salton\" or \"Equivalence\"| Association strength or other similarity indexes are obtained respectively|\n",
    "|     **Type**       | \"circle\", \"sphere\", \"mds\", \"fruchterman\", \"kamada\", \"auto\"         | Represents the layout type of the network map|\n",
    "|     **Cluster**    | \"none\", \"optimal\", \"louvain\", \"infomap\", \"edge_betweennes\", \"walktrap\", \"spinglass\", \"leading_eigen\", \"fast_greedy\"         | Type of cluster to perform|\n",
    "|     **Degree**          |  If different than \"NULL\", n is ignored        | Indicates the minimum frequency of a vertex|\n",
    "|     **Weighted**          |  \"TRUE\" or \"NULL\"        |See description above|\n",
    "|    *2- Options*          |  \n",
    "|     **noloops**          | \"TRUE\" or \"FALSE\"         | If TRUE, loops in the network are deleted|\n",
    "|     **remove.multiple**          | \"TRUE\" or \"FALSE\"         | If TRUE, multiple links are plotted using just one edge|\n",
    "|     **remove.isolates**          | \"TRUE\" or \"FALSE\"         | If TRUE, isolated vertices are not plotted|\n",
    "|     **alpha**          | *integer*  (0 to 1)     | Number from 0 (transparent) to 1 (opaque), while default is 0.5|\n",
    "|     **halo**          | \"TRUE\" or \"FALSE\"         | If TRUE, communities are plotted using different colors (default is false|\n",
    "|*3- Labels*|\n",
    "|     **Label**          |  \"TRUE\" or \"FALSE\"        | Defines if vertex labels are plotted|\n",
    "|     **Labelsize**          |  *integer*       | Label size in the plot (default is 1)|\n",
    "|     **label.color**          |  \"TRUE\" or \"FALSE\"       |  If TRUE, \"label color\" is the same as its \"cluster\"|\n",
    "|     **label.n**          |  *integer*    | Indicates the number of vertex labels to draw|\n",
    "|     **label.cex**          |   \"TRUE\" or \"FALSE\"        | If true, \"label size\" of each vertex is proportional to its \"degree\"|\n",
    "|*4- Vertex*|\n",
    "|     **n**          |  *integer*        | Indicates the number of vertices to plot|\n",
    "|     **size**          |  *integer*        | Indicates the size of each vertex (default is 3)|\n",
    "|     **size.cex**          | \"TRUE\" or \"FALSE\"         | If TRUE, vertex \"size\" is proportional to its \"degree\"|\n",
    "|*5- Edges*|\n",
    "|     **edgesize**          | *integer*         | Indicates the network edge size|\n",
    "|    **edges.min**      | *integer*| Indicates the minimum frequency of edges between two vertices (if zero, all edges are plotted)|\n",
    "|   **curved**   | \"TRUE\" or \"FALSE\"     | Default is FALSE, else, edges are plotted with an optimal curvature (number between 0 to 1) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  **3.1 - Coupling Network: Analyzing citing documents**  \n",
    "Two articles are said to be bibliographically coupled if at least one cited source appears in the reference lists of both articles. Since this depends on the number of references, \"normalizesimilarity\" can be used in networkplotting afterwards. This networks can be done over references, authors, cources or countries.  \n",
    "The strength of the bibliographic coupling of two articles, i and j is defined simply by the number of references that the\n",
    "articles have in common. **It can be calculated for: documents, authors, sources, keywords, and countries**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NetMatrix <- biblioNetwork(M, analysis=\"coupling\", network=\"authors\",sep = \";\", shortlabel = TRUE)\n",
    "net <- networkPlot( NetMatrix, Title=\"Authors' Coupling\",\n",
    "                   normalize=\"jaccard\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=NULL,                #methods\n",
    "                   noloops=TRUE, remove.multiple=FALSE, remove.isolates = FALSE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=FALSE, label.color=FALSE, label.n = 15,                            #labels\n",
    "                   n=700, size=10, size.cex=FALSE,                                                                       #vertes/nodes \n",
    "                   edgesize=1, edges.min=0.5, curved = 0)                                                               #edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### **3.2 - Co-citation Network: Analycing cited documents**  \n",
    "Two papers are linked (co-cited) if another paper cites both of them. Co-citation of two articles occurs when both are cited in a third article. Thus, co-citation is the counterpart of bibliographic coupling.  \n",
    "The useful dimensions to comment the co-citation networks are: (i) centrality and peripherality of nodes, (ii) their proximity and distance, (iii) strength of ties, (iv) clusters, (iiv) bridging contributions.  \n",
    "**IOt can be calculated for sources, references or authors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-citation with sources uses CR_SO\n",
    "## Our visualization algorithm treats each link as a spring and arranges the nodes to make links as short as possible\n",
    "NetMatrix <- biblioNetwork(M, analysis = \"co-citation\", network = \"sources\", sep = \";\")\n",
    "net <- networkPlot( NetMatrix, Title=\"Co-Citation Network\",\n",
    "                   normalize=\"jaccard\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=NULL,                #methods\n",
    "                   noloops=TRUE, remove.multiple=FALSE, remove.isolates = FALSE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=FALSE, label.color=FALSE, label.n = 15,                            #labels\n",
    "                   n=20, size=10, size.cex=TRUE,                                                                       #vertes/nodes \n",
    "                   edgesize=1, edges.min=0.5, curved = 0)                                                              #edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### **3.3 - Collaboration Network**  \n",
    "Scientific collaboration network is a network where nodes are authors and links are co-authorships as the latter is one of the most well-documented forms of scientific collaboration. Collaboration networks show how authors, institutions (e.g. universities or departments) and countries relate to others in a specific field of research. **It can be authors, universities or countries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one discovers regular study groups, hidden groups of scholars, and pivotal authors\n",
    "NetMatrix <- biblioNetwork(M, analysis = \"collaboration\",  network = \"authors\", sep = \";\")\n",
    "net <- networkPlot( NetMatrix, Title=\"Author collaboration\",\n",
    "                   normalize=\"association\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=TRUE,                #methods\n",
    "                   noloops=TRUE, remove.multiple=TRUE, remove.isolates = TRUE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=FALSE, label.color=FALSE, label.n = 100,                            #labels\n",
    "                   n=100, size=10, size.cex=TRUE,                                                                       #vertes/nodes \n",
    "                   edgesize=1, edges.min=0.5, curved = 1)                                                              #edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### **3.4 - Co-occurrences Network**  \n",
    "This can be donde over keywords (plus), authors, sources, author_keywords, titles or abstracts. For the last ones first the extraction algorithm must be used and a new column must be generated for the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-occurrence of authors in the author list of a document\n",
    "NetMatrix <- biblioNetwork(M, analysis = \"co-occurrences\", network = \"authors\", sep = \";\")\n",
    "net <- networkPlot( NetMatrix, Title=\"Authors Co-occurrences\",\n",
    "                   normalize=\"association\", type=\"fruchterman\", cluster=\"none\", degree=NULL, weighted=NULL,                #methods\n",
    "                   noloops=TRUE, remove.multiple=FALSE, remove.isolates = FALSE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=TRUE, label.color=FALSE, label.n = 15,                            #labels\n",
    "                    n = 100, size=10, size.cex=FALSE,                                                                   #vertes/nodes \n",
    "                   edgesize=1, edges.min=0.5, curved = 1)                                                              #edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### **5. - Descriptive analysis and statistics of networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we generate statistics\n",
    "netstat <- networkStat(NetMatrix)\n",
    "# Then we print the available structural properties of the network, and a short summary (showing \"k\" rows)\n",
    "names(netstat$network)\n",
    "summary(netstat, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #### **3.6 - Visualizing network (.net) files in VOSviewer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code saves the net \"networkplot\" item into a pajek netwrok file named \"vosnetwork.net\" for vosviewer (create)\n",
    "net2VOSviewer(net, vos.path=\"D:/Project R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Co-Word Analysis: The conceptual structure of a field**  \n",
    "Co-Word analysis uses the most important words or keywords of documents to study the conceptual structure of a research field (It is the only method that uses the actual content of the documents to construct a similarity measure).  \n",
    "It produces semantic maps of a field. Conceptual structure is often used to understand the topics covered by scholars (so-called research front) and identify what are the most important and the most recent issue.\n",
    "Here we map the conceptual structure by using the word co-occurrences in a bibliographic collection. It performs Correspondence Analysis (CA) or Multiple Correspondence Analysis (MCA) to draw a conceptual structure of the field and K-means clustering to identify clusters of documents which express common concepts.  \n",
    "Outputs include: **Conceptual Structure Map, Topic Dendogram, Factorial maps of the documents with the highest contributes and factorial map of the most cited documents**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conceptual Structure Function**  \n",
    "\n",
    "| Function Parameter |   Possibilities   |    Definition    |\n",
    "|:--------------------:|:-------------------:|:------------------:|\n",
    "|*1- Methods*|\n",
    "|   **Field**    | \"ID\", \"DE\", \"ID_TM\", \"DE_TM\", \"TI\" or \"AB\"| Terms extracted from Keywords plus, author's keywords, keywords plus stemmed through Porter's algorithm, Author keywords stemmed through Porter's algorithm, terms extracted from titles and terms extracted from abstracts respectively|\n",
    "|     **method**       | \"CA\", \"MCA\" or \"MDS\"       | Indicates the factorial method used to create the factorial map: Correspondence Analysis, Multiple CA or Metric Multidimensional Scaling (default is MCA)|\n",
    "|     **clust**          | \"auto\" or integer (2-8)     |Indicates the number of clusters to map |\n",
    "|     **k.max**          | *integer* (max 20) | Indicates maximum number of cluster to keep (default is 5)|\n",
    "|     **steeming**          | \"TRUE\" or \"FALSE\"         | If TRUE, Porter's Stemming algorithm is applied to all extracted terms (default is false)|\n",
    "|     **mindegree**          |  *integer*      |indicates the minimum occurrences of terms to analize and plot (default is 2)|\n",
    "|     **labelsize**          | *integer*   | Indicates the label size in the plot (default is 10)|\n",
    "|     **graph**          |  \"TRUE\" or \"FALSE\"        | If TRUE the function plots the maps otherwise they are saved in the output object (Default is true)|\n",
    "|     **documents**          | *integer*      |Indicates the number of documents to plot in the factorial map, used for CA and MCA (default is 10).|\n",
    "|*2- only for CA and MCA*|\n",
    "|     **quali.supp**    | vector    |Vector indicating the indexes of the categorical supplementary variables, used only for CA and MCA |\n",
    "|     **quanti.supp**          | vector   | Vector indicating the indexes of the quantitative supplementary variables, used only for CA and MCA |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CS$res$var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CA method over Keywords Plus\n",
    "CS <- conceptualStructure(M, field=\"DE\", method=\"MCA\", clust=\"10\", k.max = 10, stemming=FALSE, minDegree=2, labelsize=10, documents=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Thematic Evolution Analysis**  \n",
    "It is based on co-word network analysis and clustering, and begins from the \"thematicmap\" function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co-word analysis draws clusters of keywords. They are considered as themes, whose density and centrality can be used in classifying themes and mapping in a two-dimensional diagram. Thematic map is a very intuitive plot and we can analyze themes according to the quadrant in which they are placed: (1) upper-right quadrant: motor-themes; (2) lower-right quadrant: basic themes; (3) lower-left quadrant: emerging or disappearing themes; (4) upper-left quadrant: very specialized/niche themes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message(M$CR[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map=thematicMap(M, field = \"DE\", n = 250, minfreq = 5, stemming = FALSE, size = 0.5, n.labels=5, repel = TRUE)\n",
    "plot(Map$map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clusters=Map$words[order(Map$words$Cluster,-Map$words$Occurrences),]\n",
    "library(dplyr)\n",
    "CL <- Clusters %>% group_by(.data$Cluster_Label) %>% top_n(5, .data$Occurrences)\n",
    "CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First the Thematic Map function, then the thematic evolution, then the plot\n",
    "years = c(2000, 2019)\n",
    "res <- thematicMap(M, field = \"ID\", n = 250, minfreq = 5, size = 0.5, repel = TRUE)\n",
    "\n",
    "plot(res$map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Reference Publication Year Spectroscopy**  \n",
    "Method used for detecting the Historical Roots of Research Fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here sep character is the one of the Cited References column (CR) of dataframe. All timespan is considered with timespam null\n",
    "res <- rpys(M, sep = \";\", timespan = NULL, graph = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Historical Direct Citation Network**  \n",
    "The historiographic map represents a chronological networkmap of most relevant direct citations resulting from a bibliographic collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histResults <- histNetwork(M, min.citations = 10, sep = \";\")\n",
    "net <- histPlot(histResults, n=15, size = 10, labelsize=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8. Frequency Distributions and Dynamics**  \n",
    "To continue the analysis, first we need to check the separator used to split information in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With \"citations\" we calculate the distribution of \"cited citations or cited authors (only first authors for WoS database) with field=article or field=authors respectively\n",
    "(i.e. en las refencias, calcula los artículos (+source)/autores más citados devolviendolos como lista)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most cited articles and sources associated:\n",
    "CR <- citations(M, field = \"article\", sep = \";\")\n",
    "cbind(CR$Cited[1:10]) \n",
    "cbind(CR$Source[1:10])\n",
    "\n",
    "# Most cited authors\n",
    "CR <- citations(M, field = \"author\", sep = \";\")  \n",
    "cbind(CR$Cited[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Authors indexes and dominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authors' indexes\n",
    "authors=gsub(\",\",\" \",names(results$Authors)[1:10])\n",
    "indices <- Hindex(M, field = \"author\", elements=authors, sep = \";\", years = 50)\n",
    "indices$H\n",
    "\n",
    "# Authors' dominance can also be obtained through:\n",
    "dominance(results, k = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Top-Authors' Productivity over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here K is the number of authors\n",
    "authorProdOverTime(M, k = 15, graph = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sources can also be cluster through Bradford's law to obtain the most relevant journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See figure at the end\n",
    "bradford(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Local citations we measure how many times an author (or a document) included in this collection have been cited by the documents also included in the collection\n",
    "CR <- localCitations(M, sep = \";\")    \n",
    "CR$Authors[1:10,]\n",
    "CR$Papers[1:10,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sources Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Sources Growth, considering the cumulative occurrences distribution\n",
    "SW <- sourceGrowth(M, top = 5, cdf = TRUE)\n",
    "DF=melt(SW, id='Year')\n",
    "ggplot(DF,aes(Year,value, group=variable, color=variable))+geom_line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **OTHERS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Keywordgrowth**  \n",
    "KeywordGrwoth calculates for the top X keywords (DE or ID) the cumulative or punctual distribution, returning a dataframe with each year of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KW_PDF <- KeywordGrowth(M, Tag = \"DE\", sep = \";\", top = 4000, cdf = FALSE)\n",
    "KW_CDF <- KeywordGrowth(M, Tag = \"DE\", sep = \";\", top = 4000, cdf = TRUE)\n",
    "write.csv(KW_PDF,'KW_PDF.csv')\n",
    "write.csv(KW_CDF,'KW_CDF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TERM EXTRACTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "termExtraction(M, Field = \"TI\", stemming = FALSE,language = \"english\", remove.numbers = TRUE, \n",
    "               remove.terms = NULL,keep.terms = NULL, synonyms = NULL, verbose = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# **Final Outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In vosviewer\n",
    "- The attraction/repulsion helps put closer or further the terms\n",
    "- the clustering options help reach the desired ammount of clusters to graph\n",
    "\n",
    "In R:\n",
    "- The number of elements displayed is crucial for visualization. \n",
    "- Leave type to auto and then edit it through vosviewer\n",
    "- Using weigthed True allows to display both \"total link strength\" or \"links\" as a visualization\n",
    "- Looks better without multiples and isolated ones\n",
    "- Degree messes all up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Co-Occurrences of: Author Keywords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Full DB, Normal, weighted. I proved puting more n (175, 200, 225, 250), but just gets more little clusters \n",
    "# located far away from the central ones (non-related)\n",
    "# Dont plot Principal Component Analysis and Dynamic Programming\n",
    "# Specs: Clustering (resolution = 0.6, min cluster size =1). Layout (2 Att. and 1 Rep.) Lines (min strength 3 and max lines 1483)\n",
    "# 4 clusters, 1483 links and 2724 total links strenght\n",
    "# Migth be a good idea to remove 3-5 terms that arent actually well connected\n",
    "NetMatrix <- biblioNetwork(M, analysis = \"co-occurrences\", network = \"author_keywords\", sep = \";\")\n",
    "net <- networkPlot(NetMatrix, Title=\"Author Keywords Co-occurrences\",\n",
    "                   normalize=\"association\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=TRUE,                #methods\n",
    "                   noloops=TRUE, remove.multiple=TRUE, remove.isolates = TRUE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=TRUE, label.color=FALSE, label.n = 150,                            #labels\n",
    "                   n = 150, size=10, size.cex=TRUE,                                                                   #vertes/nodes \n",
    "                   edgesize=1, edges.min=0.5, curved = 0)                                                              #edges\n",
    "#net2VOSviewer(net, vos.path=\"Outputs/DE_Co_occurrences/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netstat <- networkStat(NetMatrix, stat = \"all\", type = \"authority\")\n",
    "# Then we print the available structural properties of the network, and a short summary (showing \"k\" rows)\n",
    "names(netstat$network)\n",
    "summary(netstat, k=50)\n",
    "# Type: \"degree\", \"closeness\", \"betweenness\",\"eigenvector\",\"pagerank\",\"hub\",\"authority\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i think this one will be easyer to understand once we do the all revision. Like identifying small clusters from each keystone\n",
    "# paper or colouring each paper accordingly to the colors in vosviewer\n",
    "\n",
    "# 2 - GW_ABM DATABASE, Normal, weighted, but less N\n",
    "# Specs: Clustering (resolution = 0.03, min cluster size =10). Layout (3 Att. and 1 Rep.) Lines (min strength 0 and max lines 1000)\n",
    "# 3 clusters, 652 links and 677 total links strength\n",
    "# Migth be a good idea to remove 3-5 terms that arent actually well connected\n",
    "NetMatrix <- biblioNetwork(M, analysis = \"co-occurrences\", network = \"author_keywords\", sep = \";\")\n",
    "net <- networkPlot( NetMatrix, Title=\"Author Keywords Co-occurrences\",\n",
    "                   normalize=\"association\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=TRUE,                #methods\n",
    "                   noloops=TRUE, remove.multiple=TRUE, remove.isolates = TRUE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=TRUE, label.color=FALSE, label.n = 500,                            #labels\n",
    "                   n = 500, size=10, size.cex=TRUE,                                                                   #vertes/nodes \n",
    "                   edgesize=1, edges.min=0.5, curved = 0)                                                              #edges\n",
    "net2VOSviewer(net, vos.path=\"Outputs/DE_Co_occurrences/2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Co-Citation of Authors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is an error on how the author names are being handled. Specifically Lempert appears in 4 different ways, but the Authors\n",
    "# column looks perfectly fine so its the Citing references column that has the issue.\n",
    "\n",
    "# 1 Full Database, weighted\n",
    "# Specs: Clustering (resolution = 0.90, min cluster size =1). Layout (4 Att. and 0 Rep.) Lines (min strength 0 and max lines 1000)\n",
    "# 5 clusters, 21865 links and 75738 total links strength\n",
    "# Migth be a good idea to remove terms that arent actually well connected\n",
    "\n",
    "NetMatrix <- biblioNetwork(M, analysis = \"co-citation\", network = \"authors\", sep = \";\")\n",
    "net <- networkPlot( NetMatrix, Title=\"Authors Co-Citation Network\",\n",
    "                   normalize=\"association\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=TRUE,                #methods\n",
    "                   noloops=TRUE, remove.multiple=TRUE, remove.isolates = TRUE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=FALSE, label.color=FALSE, label.n = 300,                            #labels\n",
    "                   n=300, size=10, size.cex=TRUE,                                                                       #vertes/nodes \n",
    "                   edgesize=1, edges.min=0.5, curved = 0)\n",
    "net2VOSviewer(net, vos.path=\"Outputs/Co-Citations/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bibliographic Coupling of Authors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Full Database, weighted\n",
    "# Specs: Clustering (resolution = 1.05, min cluster size =10). Layout (3 Att. and 0 Rep.) Lines (min strength 1 and max lines 1000)\n",
    "# 6 clusters, 104650 links and 2456871 total links strength, 500 elements\n",
    "# Migth be a good idea to remove terms that arent actually well connected\n",
    "\n",
    "NetMatrix <- biblioNetwork(M, analysis = \"coupling\", network = \"authors\",sep = \";\", shortlabel = FALSE)\n",
    "net <- networkPlot( NetMatrix, Title=\"Authors' Coupling\",\n",
    "                   normalize=\"association\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=TRUE,                #methods\n",
    "                   noloops=TRUE, remove.multiple=TRUE, remove.isolates = TRUE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=FALSE, label.color=FALSE, label.n = 500,                            #labels\n",
    "                   n=500, size=10, size.cex=TRUE,                                                                       #vertes/nodes \n",
    "                   edgesize=1, edges.min=0.5, curved = 0)\n",
    "net2VOSviewer(net, vos.path=\"Outputs/Coupling/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 (new) Full Database, weighted\n",
    "# Specs: Clustering (resolution = 1.05, min cluster size =10). Layout (3 Att. and 0 Rep.) Lines (min strength 1 and max lines 1000)\n",
    "# 6 clusters, 104650 links and 2456871 total links strength, 500 elements\n",
    "# Migth be a good idea to remove terms that arent actually well connected\n",
    "\n",
    "NetMatrix <- biblioNetwork(M, analysis = \"coupling\", network = \"authors\",sep = \";\", shortlabel = FALSE)\n",
    "net <- networkPlot( NetMatrix, Title=\"Authors' Coupling\",\n",
    "                   normalize=\"association\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=TRUE,                #methods\n",
    "                   noloops=TRUE, remove.multiple=TRUE, remove.isolates = TRUE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=FALSE, label.color=FALSE, label.n = 600,                            #labels\n",
    "                   n=600, size=10, size.cex=TRUE,                                                                       #vertes/nodes \n",
    "                   edgesize=1, edges.min=0.5, curved = 0)\n",
    "net2VOSviewer(net, vos.path=\"Outputs/Coupling/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 (new) Full Database, weighted\n",
    "# Specs: Clustering (resolution = 1.05, min cluster size =10). Layout (3 Att. and 0 Rep.) Lines (min strength 1 and max lines 1000)\n",
    "# 6 clusters, 104650 links and 2456871 total links strength, 500 elements\n",
    "# Migth be a good idea to remove terms that arent actually well connected\n",
    "\n",
    "NetMatrix <- biblioNetwork(M, analysis = \"coupling\", network = \"authors\",sep = \";\", shortlabel = FALSE)\n",
    "net <- networkPlot( NetMatrix, Title=\"Authors' Coupling\",\n",
    "                   normalize=\"association\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=TRUE,                #methods\n",
    "                   noloops=TRUE, remove.multiple=TRUE, remove.isolates = TRUE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=FALSE, label.color=FALSE, label.n = 800,                            #labels\n",
    "                   n=800, size=10, size.cex=TRUE,                                                                       #vertes/nodes \n",
    "                   edgesize=1, edges.min=0.5, curved = 0)\n",
    "net2VOSviewer(net, vos.path=\"Outputs/Coupling/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netstat <- networkStat(NetMatrix, stat = \"all\", type = \"authority\")\n",
    "# Then we print the available structural properties of the network, and a short summary (showing \"k\" rows)\n",
    "names(netstat$network)\n",
    "summary(netstat,k=100)\n",
    "# Type: \"degree\", \"closeness\", \"betweenness\",\"eigenvector\",\"pagerank\",\"hub\",\"authority\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Collaboration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one uses AU_CO metatag\n",
    "NetMatrix <- biblioNetwork(M, analysis = \"collaboration\",  network = \"countries\", sep = \";\")\n",
    "net <- networkPlot( NetMatrix, Title=\"Country collaboration\",\n",
    "                   normalize=\"association\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=TRUE,                #methods\n",
    "                   noloops=TRUE, remove.multiple=TRUE, remove.isolates = TRUE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=FALSE, label.color=FALSE,                            #labels\n",
    "                    n = 30, size=10, size.cex=TRUE,                                                   #vertes/nodes \n",
    "                   edgesize=1, edges.min=0.5, curved = 0)                                                              #edges\n",
    "net2VOSviewer(net, vos.path=\"Outputs/Collaboration/1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Network Stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netstat <- networkStat(NetMatrix, stat = \"all\", type = \"authority\")\n",
    "# Then we print the available structural properties of the network, and a short summary (showing \"k\" rows)\n",
    "names(netstat$network)\n",
    "summary(netstat)\n",
    "# Type: \"degree\", \"closeness\", \"betweenness\",\"eigenvector\",\"pagerank\",\"hub\",\"authority\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
