{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "**Bibliometrix Analysis in R**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook documents a novel workflow for performing bibliometric analysis of any scientific topic. It relies on the Bibliometrix-R package to compile bibliographic information from diverse search engines, and cleans the information through the *Python-Notebook Bibliometrix*, returning diverse outputs.  \n",
    "\n",
    "----\n",
    "\n",
    "**General WorkFlow**  \n",
    "\n",
    "Download bibliographic files  \n",
    "*Out -> .BibTeX*\n",
    "\n",
    "Python-Notebook:\n",
    "1. Import libraries\n",
    "2. Create working Folders  \n",
    "\n",
    "R-Notebook\n",
    "1. Import libraries\n",
    "2. Database compilation  \n",
    "*Out -> “db_r_to_py.csv”*\n",
    "\n",
    "\n",
    "Python-Notebook:\n",
    "1. Cleaning  \n",
    "*Out -> \"db_py_to_r.csv\"*\n",
    "\n",
    "\n",
    "Outputs  \n",
    "I) R-Notebook\n",
    "1. Sankeys\n",
    "2. Networks (move with python)\n",
    "3. Co-word analysis\n",
    "4. Thematic evolution\n",
    "\n",
    "\n",
    "II) Python-Notebook\n",
    "1. Zotero\n",
    "2. Move Networks\n",
    "3. Annual scientific production\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Network_science#Node_centrality\n",
    "https://en.wikipedia.org/wiki/Centrality#Eigenvector_centrality\n",
    "Density: Ratio of the number of edges to the number of possible edges.\n",
    "\n",
    "Network Closure (Transitivity): A measure of the completeness of relational triads. An individual's assumption of network closure (i.e. that their friends are also friends) is called transitivity.\n",
    "\n",
    "Diameter: Indicates how separated nodes are from one another and is representative of the linear size of a network. It is the shortest distance between the two most distant nodes in the network. In other words, once the shortest path length from every node to all other nodes is calculated, the diameter is the longest of all the calculated path lengths. \n",
    "\n",
    "Degree Centrality: Centrality indexes quantify the centrality of a node. The \"importance\" or \"influence\" (in a variety of senses) of a particular node (or group) within a network. Degree centrality specifically is defined as the number of links incident upon a node (i.e., the number of ties that a node has). The degree can be interpreted in terms of the immediate risk of a node for catching whatever is flowing through the network (such as a virus, or some information). Different centrality indices encode different contexts for the word \"importance.\" (i.e. connecting with important nodes or not for example).\n",
    "The betweenness centrality, for example, considers a node highly important if it form bridges between many other nodes. The eigenvalue centrality, in contrast, considers a node highly important if many other highly important nodes link to it (It assigns relative scores to all nodes in the network based on the concept that connections to high-scoring nodes contribute more to the score of the node in question than equal connections to low-scoring nodes. To define an absolute score one must normalise the eigenvector, e.g., such that the sum over all vertices is 1 or the total number of vertices n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# **Set-up**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DEPENDENCIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To cite bibliometrix in publications, please use:\n",
      "\n",
      "Aria, M. & Cuccurullo, C. (2017) bibliometrix: An R-tool for comprehensive science mapping analysis, Journal of Informetrics, 11(4), pp 959-975, Elsevier.\n",
      "                        \n",
      "\n",
      "http:\\\\www.bibliometrix.org\n",
      "\n",
      "                        \n",
      "To start with the shiny web-interface, please digit:\n",
      "biblioshiny()\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(bibliometrix)\n",
    "library(ggplot2)\n",
    "library(reshape2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **WORKING DIRECTORY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/Users/macadmin/Desktop/Projects/Research Quilting/Jupyter notebooks'"
      ],
      "text/latex": [
       "'/Users/macadmin/Desktop/Projects/Research Quilting/Jupyter notebooks'"
      ],
      "text/markdown": [
       "'/Users/macadmin/Desktop/Projects/Research Quilting/Jupyter notebooks'"
      ],
      "text/plain": [
       "[1] \"/Users/macadmin/Desktop/Projects/Research Quilting/Jupyter notebooks\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'/Users/macadmin/Desktop/Projects/Research Quilting'"
      ],
      "text/latex": [
       "'/Users/macadmin/Desktop/Projects/Research Quilting'"
      ],
      "text/markdown": [
       "'/Users/macadmin/Desktop/Projects/Research Quilting'"
      ],
      "text/plain": [
       "[1] \"/Users/macadmin/Desktop/Projects/Research Quilting\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If there is a warning message, simply add one more line to the text file\n",
    "df2 <- read.delim(file = 'Working directory for R.txt', header = FALSE, sep = \"\\t\", dec = \",\") # read the file\n",
    "\n",
    "# Print current working directory:\n",
    "getwd()\n",
    "\n",
    "# Set new working directory:\n",
    "setwd(as.character(df2[['V1']]))\n",
    "getwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(df2)    # columns names of the dataframe\n",
    "str(df2)      # viewing the summary of the dataframe\n",
    "df2[['V1']]   # accessing specific cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Database Compilation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this step we convert and merge the downloaded bibliographic files (.BibTex) into a single dataframe, and export it to an Excel file for cleaning in Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the BibTeX files here stored in Keywords Searches folder \n",
    "SDB <- readFiles(\"Keyword Searches/ABM & GW/Input Data/GWABM_SCOPUS.bib\")\n",
    "WDB <- readFiles(\"Keyword Searches/ABM & GW/Input Data/GWABM_WOS.bib\")\n",
    "#WDB2 <- readFiles(\"Keyword Searches/Floods/Input Data/loods_WOS2.bib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting BibTeX to Dataframes\n",
    "SDB_DF <- convert2df(SDB, dbsource = \"scopus\", format = \"bibtex\")\n",
    "WDB_DF <- convert2df(WDB, dbsource = \"isi\", format = \"bibtex\")\n",
    "#WDB_DF_2 <- convert2df(WDB2, dbsource = \"isi\", format = \"bibtex\")\n",
    "\n",
    "# We merge dataframes and remove duplicates\n",
    "Merged <- mergeDbSources(WDB_DF, SDB_DF, remove.duplicated=TRUE)\n",
    "#Merged <- mergeDbSources(WDB_DF, SDB_DF, WDB_DF_2,remove.duplicated=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We also remove duplicates through the Titles field of the Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove duplicates by searching through the title field\n",
    "New_Merged <- duplicatedMatching(Merged, Field = \"TI\", tol = 0.90)\n",
    "message(nrow(New_Merged), ' rows and ', ncol(New_Merged), ' columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we extract a set of other field tags, different from the standard WoS/SCOPUS codify. These metatags are added to the Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M <- New_Merged\n",
    "# Here we chek the cited references [CR] column, obtaining a \";\" separator\n",
    "#message(M$CR[1])  \n",
    "message(nrow(M), ' rows and ', ncol(M), ' columns')\n",
    "\n",
    "# This code retrieves FIELD TAGS (e.g. references authors) not included in the dataframe generated but still in the database and adds them as new columns\n",
    "M <- metaTagExtraction(M, Field = \"CR_AU\", sep = \";\")   # First author of each cited reference\n",
    "M <- metaTagExtraction(M, Field = \"CR_SO\", sep = \";\")   # Source of each cited reference\n",
    "M <- metaTagExtraction(M, Field = \"AU_CO\", sep = \";\")   # Country of affiliation for each co-author\n",
    "M <- metaTagExtraction(M, Field = \"AU1_CO\", sep = \";\")  # Country of affiliation for the first author\n",
    "M <- metaTagExtraction(M, Field = \"AU_UN\", sep = \";\")   # University of affiliation  for each co-author and the corresponding author\n",
    "M <- metaTagExtraction(M, Field = \"SR\", sep = \";\")      # Short tag of the document\n",
    "message(nrow(M), ' rows and ', ncol(M), ' columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally we create a .csv file for further cleaning of the database through Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(M,'db_r_to_py.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Database cleaning through \"Python-Notebook Bibliometrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Excel file (var: db_r_to_py.csv) is now ready to be cleaned on the \"Python-Notebook Bibliometrix\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reupdate of database to Bibliometrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#M <- read.csv(file = \"db_py_to_r.csv\")\n",
    "M <- read.csv(file = \"Merged DB (GW-ABM,SH,PM,TC,EM).csv\")\n",
    "M$DE<- as.character(M$DE)\n",
    "M$SO<- as.character(M$SO)\n",
    "M$AU_UN<- as.character(M$AU_UN)\n",
    "M$AU_CO<- as.character(M$AU_CO)\n",
    "M$AU<- as.character(M$AU)\n",
    "M$AU1_CO<- as.character(M$AU1_CO)\n",
    "M$AU_UN<- as.character(M$AU_UN)\n",
    "M$AU_UN_NR<- as.logical(M$AU_UN_NR)\n",
    "M$AU1_UN<- as.character(M$AU1_UN)\n",
    "M$CR_AU<- as.character(M$CR_AU)\n",
    "M$CR_SO<- as.character(M$CR_SO)\n",
    "M$DT<- as.character(M$DT)\n",
    "M$DT2<- as.character(M$DT2)\n",
    "M$ID<- as.character(M$ID)\n",
    "M$JI<- as.character(M$JI)\n",
    "M$LA<- as.character(M$LA)\n",
    "M$PN<- as.character(M$PN)\n",
    "M$PP<- as.character(M$PP)\n",
    "#M$PU<- as.character(M$PU)\n",
    "M$PY<- as.numeric(M$PY)\n",
    "M$RP<- as.character(M$RP)\n",
    "M$SN<- as.character(M$SN)\n",
    "M$AB<- as.character(M$AB)\n",
    "M$DB<- as.character(M$DB)\n",
    "M$CR<- as.character(M$CR)\n",
    "M$SR<- as.character(M$SR)\n",
    "M$AR<- as.character(M$AR)\n",
    "M$C1<- as.character(M$C1)\n",
    "M$DI<- as.character(M$DI)\n",
    "M$SR_FULL<- as.character(M$SR_FULL)\n",
    "M$TC<- as.numeric(M$TC)\n",
    "M$TI<- as.character(M$TI)\n",
    "M$VL<- as.character(M$VL)\n",
    "\n",
    "#M$FU<- as.character(M$FU)\n",
    "#M$BN<- as.character(M$BN)\n",
    "message('Database has ', nrow(M), ' rows and ', ncol(M), ' columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# **Outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Main Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The variable \"results\" saves the bibliographic summary (here \"k\" indicates how many rows will be printed in each table)\n",
    "results <- biblioAnalysis(M, sep = \";\")     \n",
    "options(width=100)\n",
    "S <- summary(object = results, k = 20, pause = FALSE)\n",
    "plot(x = results, k = 40, pause = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sankey Plots**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interactively visualize the main items of three fields and how they are related. The larger flows (arrow widths) can be easily visualized. The width is proportional to the quantity represented. Advantages: highlight main flows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here \"n\" indicates the number of items to plot in each field, and width and height are in pixels\n",
    "threeFieldsPlot(M, fields = c(\"SO\", \"DE\", \"AU1_CO\"), n = c(641, 3989, 4682), width = 1000, height = 900)   # Authors - Author Keywords - Sources (Journal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## **Networks** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Co-occurrences of Author Keywords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NetMatrix <- biblioNetwork(M, analysis = \"co-occurrences\", network = \"author_keywords\", sep = \";\")\n",
    "net <- networkPlot(NetMatrix, Title=\"Author Keywords Co-occurrences\",\n",
    "                   normalize=\"association\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=TRUE,                #methods\n",
    "                   noloops=TRUE, remove.multiple=FALSE, remove.isolates = TRUE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=TRUE, label.color=FALSE, label.n = 150,                            #labels\n",
    "                   n = 4000, size=10, size.cex=TRUE,                                                                   #vertes/nodes \n",
    "                   edgesize=10, edges.min=1, curved = 0)                                                              #edges\n",
    "net2VOSviewer(net, vos.path=\"Temporal Outputs/Co-occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Co-Citation of Authors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NetMatrix <- biblioNetwork(M, analysis = \"co-citation\", network = \"authors\", sep = \";\")\n",
    "net <- networkPlot( NetMatrix, Title=\"Authors Co-Citation Network\",\n",
    "                   normalize=\"association\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=TRUE,                #methods\n",
    "                   noloops=TRUE, remove.multiple=TRUE, remove.isolates = TRUE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=FALSE, label.color=FALSE, label.n = 300,                            #labels\n",
    "                   n=300, size=10, size.cex=TRUE,                                                                       #vertes/nodes \n",
    "                   edgesize=1, edges.min=0.5, curved = 0)\n",
    "net2VOSviewer(net, vos.path=\"Temporal Outputs/Co-citations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bibliographic Coupling of Authors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NetMatrix <- biblioNetwork(M, analysis = \"coupling\", network = \"authors\",sep = \";\", shortlabel = FALSE)\n",
    "net <- networkPlot( NetMatrix, Title=\"Authors' Coupling\",\n",
    "                   normalize=\"association\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=TRUE,                #methods\n",
    "                   noloops=TRUE, remove.multiple=TRUE, remove.isolates = TRUE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=FALSE, label.color=FALSE, label.n = 800,                            #labels\n",
    "                   n=800, size=10, size.cex=TRUE,                                                                       #vertes/nodes \n",
    "                   edgesize=1, edges.min=0.5, curved = 0)\n",
    "net2VOSviewer(net, vos.path=\"Temporal Outputs/Bibliographic Coupling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Collaboration of Countries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one uses AU_CO metatag\n",
    "NetMatrix <- biblioNetwork(M, analysis = \"collaboration\",  network = \"countries\", sep = \";\")\n",
    "net <- networkPlot( NetMatrix, Title=\"Country collaboration\",\n",
    "                   normalize=\"association\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=TRUE,                #methods\n",
    "                   noloops=TRUE, remove.multiple=TRUE, remove.isolates = TRUE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=FALSE, label.color=FALSE,                            #labels\n",
    "                    n = 30, size=10, size.cex=TRUE,                                                   #vertes/nodes \n",
    "                   edgesize=1, edges.min=0.5, curved = 0)                                                              #edges\n",
    "net2VOSviewer(net, vos.path=\"Temporal Outputs/Collaborations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Networks Statistics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we print the available structural properties of the network, and a short summary (showing \"k\" rows)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netstat <- networkStat(NetMatrix, stat = \"all\", type = \"authority\")\n",
    "names(netstat$network)\n",
    "summary(netstat,k=100)\n",
    "# Type: \"degree\", \"closeness\", \"betweenness\",\"eigenvector\",\"pagerank\",\"hub\",\"authority\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Mining**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we extract terms from textual fields of a manuscript (abstract, title, author’s keywords, keywords plus). Specifically, we start with Titles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scientometrics <- termExtraction(M, Field = \"TI\", stemming = FALSE,language = \"english\", remove.numbers = TRUE, \n",
    "               remove.terms = NULL,keep.terms = NULL, synonyms = NULL, verbose = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we see the terms extracted from the first 10 titles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scientometrics$TI_TM[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we extract terms from abstracts and show the terms extracted from the first abstract**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scientometrics <- termExtraction(M, Field = \"AB\", stemming = FALSE,language = \"english\", remove.numbers = TRUE, \n",
    "               remove.terms = NULL,keep.terms = NULL, synonyms = NULL, verbose = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scientometrics$AB_TM[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Co-Word Analysis: The conceptual structure of a field**  \n",
    "<div style=\"text-align: justify\"> Co-Word analysis uses the most important words or keywords of documents to study the conceptual structure of a research field (It is the only method that uses the actual content of the documents to construct a similarity measure).  \n",
    "It produces semantic maps of a field. Conceptual structure is often used to understand the topics covered by scholars (so-called research front) and identify what are the most important and the most recent issue.\n",
    "Here we map the conceptual structure by using the word co-occurrences in a bibliographic collection. It performs Correspondence Analysis (CA) or Multiple Correspondence Analysis (MCA) to draw a conceptual structure of the field and K-means clustering to identify clusters of documents which express common concepts. </div>  \n",
    "Outputs include:  \n",
    "\n",
    "- Conceptual Structure Map\n",
    "- Topic Dendogram\n",
    "- Factorial maps of the documents with the highest contributes and \n",
    "- factorial map of the most cited documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conceptual Structure Function**  \n",
    "\n",
    "| Function Parameter |   Possibilities   |    Definition    |\n",
    "|:--------------------:|:-------------------:|:------------------:|\n",
    "|*1- Methods*|\n",
    "|   **Field**    | \"ID\", \"DE\", \"ID_TM\", \"DE_TM\", \"TI\" or \"AB\"| Terms extracted from Keywords plus, author's keywords, keywords plus stemmed through Porter's algorithm, Author keywords stemmed through Porter's algorithm, terms extracted from titles and terms extracted from abstracts respectively|\n",
    "|     **method**       | \"CA\", \"MCA\" or \"MDS\"       | Indicates the factorial method used to create the factorial map: Correspondence Analysis, Multiple CA or Metric Multidimensional Scaling (default is MCA)|\n",
    "|     **clust**          | \"auto\" or integer (2-8)     |Indicates the number of clusters to map |\n",
    "|     **k.max**          | *integer* (max 20) | Indicates maximum number of cluster to keep (default is 5)|\n",
    "|     **steeming**          | \"TRUE\" or \"FALSE\"         | If TRUE, Porter's Stemming algorithm is applied to all extracted terms (default is false)|\n",
    "|     **mindegree**          |  *integer*      |indicates the minimum occurrences of terms to analize and plot (default is 2)|\n",
    "|     **labelsize**          | *integer*   | Indicates the label size in the plot (default is 10)|\n",
    "|     **graph**          |  \"TRUE\" or \"FALSE\"        | If TRUE the function plots the maps otherwise they are saved in the output object (Default is true)|\n",
    "|     **documents**          | *integer*      |Indicates the number of documents to plot in the factorial map, used for CA and MCA (default is 10).|\n",
    "|*2- only for CA and MCA*|\n",
    "|     **quali.supp**    | vector    |Vector indicating the indexes of the categorical supplementary variables, used only for CA and MCA |\n",
    "|     **quanti.supp**          | vector   | Vector indicating the indexes of the quantitative supplementary variables, used only for CA and MCA |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CA method over Keywords Plus\n",
    "CS <- conceptualStructure(M, field=\"DE\", method=\"MCA\", clust=\"3\", k.max = 10, stemming=FALSE, minDegree=10, labelsize=10, documents=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Thematic Evolution Analysis**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co-word analysis draws clusters of keywords. They are considered as themes, whose density and centrality can be used in classifying themes and mapping in a two-dimensional diagram. Thematic map is a very intuitive plot and we can analyze themes according to the quadrant in which they are placed: (1) upper-right quadrant: motor-themes; (2) lower-right quadrant: basic themes; (3) lower-left quadrant: emerging or disappearing themes; (4) upper-left quadrant: very specialized/niche themes.  \n",
    "The Thematic Map funciton creates a thematic map based on co-word network analysis and clustering. The methodology is inspired by the proposal of Cobo et al. (2011)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First we generate Thematic Maps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res <- thematicMap(M, field = \"DE\", n = 2000, minfreq = 3, stemming = FALSE, size = 0.4, n.labels=3, repel = TRUE)\n",
    "plot(res$map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second we produce a Thematic Evolution Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = c(2005,2018)\n",
    "nexus <- thematicEvolution(M, field = \"DE\", years=years, n = 10, minFreq = 7, size = 0.5, stemming = FALSE, n.labels = 1, repel = TRUE)\n",
    "plot(nexus$map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the Thematic Maps we can finally produce the Thematic Evolution Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TE <- plotThematicEvolution(nexus$Nodes, nexus$Edges, measure = \"inclusion\", min.flow = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reference Publication Year Spectroscopy**  \n",
    "rpys computes a Reference Publication Year Spectroscopy for detecting the Historical Roots of Research Fields. The method was introduced by Marx et al., 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = c(2000,2018)\n",
    "res <- rpys(M, sep = \";\", timespan = years, graph = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Historical Direct Citation Network**  \n",
    "The historiographic map (proposed by E. Garfield) represents a chronological networkmap of most relevant direct citations resulting from a bibliographic collection. We first create the historical citation network, and then we plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histResults <- histNetwork(M, min.citations = 10, sep = \";\", verbose=FALSE)\n",
    "net <- histPlot(histResults, n=50, size = 5, labelsize=7, verbose=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
