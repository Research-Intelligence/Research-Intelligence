{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "**Bibliometrix Analysis in R**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook documents a novel workflow for performing bibliometric analysis of any scientific topic. It relies on the Bibliometrix-R package to compile bibliographic information from diverse search engines, and cleans the information through the *Python-Notebook Bibliometrix*, returning diverse outputs.  \n",
    "\n",
    "----\n",
    "\n",
    "**General WorkFlow**  \n",
    "\n",
    "Download bibliographic files  \n",
    "*Out -> .BibTeX*\n",
    "\n",
    "Python-Notebook:\n",
    "1. Import libraries\n",
    "2. Create working Folders  \n",
    "\n",
    "R-Notebook\n",
    "1. Import libraries\n",
    "2. Database compilation  \n",
    "*Out -> “db_r_to_py.csv”*\n",
    "\n",
    "\n",
    "Python-Notebook:\n",
    "1. Cleaning  \n",
    "*Out -> \"db_py_to_r.csv\"*\n",
    "\n",
    "\n",
    "Outputs  \n",
    "I) R-Notebook\n",
    "1. Sankeys\n",
    "2. Networks (move with python)\n",
    "3. Co-word analysis\n",
    "4. Thematic evolution\n",
    "\n",
    "\n",
    "II) Python-Notebook\n",
    "1. Zotero\n",
    "2. Move Networks\n",
    "3. Annual scientific production\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Network_science#Node_centrality\n",
    "https://en.wikipedia.org/wiki/Centrality#Eigenvector_centrality\n",
    "Density: Ratio of the number of edges to the number of possible edges.\n",
    "\n",
    "Network Closure (Transitivity): A measure of the completeness of relational triads. An individual's assumption of network closure (i.e. that their friends are also friends) is called transitivity.\n",
    "\n",
    "Diameter: Indicates how separated nodes are from one another and is representative of the linear size of a network. It is the shortest distance between the two most distant nodes in the network. In other words, once the shortest path length from every node to all other nodes is calculated, the diameter is the longest of all the calculated path lengths. \n",
    "\n",
    "Degree Centrality: Centrality indexes quantify the centrality of a node. The \"importance\" or \"influence\" (in a variety of senses) of a particular node (or group) within a network. Degree centrality specifically is defined as the number of links incident upon a node (i.e., the number of ties that a node has). The degree can be interpreted in terms of the immediate risk of a node for catching whatever is flowing through the network (such as a virus, or some information). Different centrality indices encode different contexts for the word \"importance.\" (i.e. connecting with important nodes or not for example).\n",
    "The betweenness centrality, for example, considers a node highly important if it form bridges between many other nodes. The eigenvalue centrality, in contrast, considers a node highly important if many other highly important nodes link to it (It assigns relative scores to all nodes in the network based on the concept that connections to high-scoring nodes contribute more to the score of the node in question than equal connections to low-scoring nodes. To define an absolute score one must normalise the eigenvector, e.g., such that the sum over all vertices is 1 or the total number of vertices n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# **Set-up**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To cite bibliometrix in publications, please use:\n",
      "\n",
      "Aria, M. & Cuccurullo, C. (2017) bibliometrix: An R-tool for comprehensive science mapping analysis, Journal of Informetrics, 11(4), pp 959-975, Elsevier.\n",
      "                        \n",
      "\n",
      "http:\\\\www.bibliometrix.org\n",
      "\n",
      "                        \n",
      "To start with the shiny web-interface, please digit:\n",
      "biblioshiny()\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(bibliometrix)\n",
    "library(ggplot2)\n",
    "library(reshape2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WORKING DIRECTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we read the text file generated in the python notebook, to set the appropriate working directory with `setwd()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/Users/macadmin/Desktop/Projects/Research Quilting/Jupyter notebooks'"
      ],
      "text/latex": [
       "'/Users/macadmin/Desktop/Projects/Research Quilting/Jupyter notebooks'"
      ],
      "text/markdown": [
       "'/Users/macadmin/Desktop/Projects/Research Quilting/Jupyter notebooks'"
      ],
      "text/plain": [
       "[1] \"/Users/macadmin/Desktop/Projects/Research Quilting/Jupyter notebooks\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'/Users/macadmin/Desktop/Projects/Research Quilting'"
      ],
      "text/latex": [
       "'/Users/macadmin/Desktop/Projects/Research Quilting'"
      ],
      "text/markdown": [
       "'/Users/macadmin/Desktop/Projects/Research Quilting'"
      ],
      "text/plain": [
       "[1] \"/Users/macadmin/Desktop/Projects/Research Quilting\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# If there is a warning message, simply add one more line to the text file\n",
    "wd <- read.delim(file = 'Working directory for R.txt', header = FALSE, sep = \"\\t\", dec = \",\") # read the file\n",
    "\n",
    "# Print current working directory:\n",
    "getwd()\n",
    "\n",
    "# Set new working directory:\n",
    "setwd(as.character(wd[['V1']]))\n",
    "getwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Database Compilation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this step we convert and merge the downloaded bibliographic files (.BibTex) into a single dataframe, and export it to an Excel file for cleaning in Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All input BiBTex files are stored in the \"Input Data\" Folder. Here we may read several of them either from Scopus or WOS:\n",
    "SDB <- readFiles(\"Keyword Searches/ABM & GW/Input Data/GWABM_SCOPUS.bib\")\n",
    "WDB <- readFiles(\"Keyword Searches/ABM & GW/Input Data/GWABM_WOS.bib\")\n",
    "#WDB2 <- readFiles(\"Keyword Searches/Floods/Input Data/loods_WOS2.bib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting your scopus collection into a bibliographic dataframe\n",
      "\n",
      "Articles extracted   60 \n",
      "Done!\n",
      "\n",
      "\n",
      "Generating affiliation field tag AU_UN from C1:  Done!\n",
      "\n",
      "\n",
      "Converting your isi collection into a bibliographic dataframe\n",
      "\n",
      "Articles extracted   45 \n",
      "Done!\n",
      "\n",
      "\n",
      "Generating affiliation field tag AU_UN from C1:  Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here we convert the just read BibTeX files to DataFrames:\n",
    "SDB_DF <- convert2df(SDB, dbsource = \"scopus\", format = \"bibtex\")\n",
    "WDB_DF <- convert2df(WDB, dbsource = \"isi\", format = \"bibtex\")\n",
    "#WDB_DF_2 <- convert2df(WDB2, dbsource = \"isi\", format = \"bibtex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 34 duplicated documents have been removed\n"
     ]
    }
   ],
   "source": [
    "# Now we merge the DataFrames and remove duplicates:\n",
    "Merged <- mergeDbSources(WDB_DF, SDB_DF, remove.duplicated=TRUE)\n",
    "\n",
    "# In case we are working with more than 2 BibTeX/dataframes we can apply:\n",
    "#Merged <- mergeDbSources(WDB_DF, SDB_DF, WDB_DF_2,remove.duplicated=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We also remove duplicates through the Titles field of the Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71 rows and 28 columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We remove duplicates by searching through the title field\n",
    "M <- duplicatedMatching(Merged, Field = \"TI\", tol = 0.90)\n",
    "message(nrow(M), ' rows and ', ncol(M), ' columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we further complete the DataFrame by extracting and inserting a set of other field tags called: Metatags.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BEGIN ZB, 1981, J GEOL, V89, P497, DOI 10.1086/628610.;BOGGS, 1995, PRINCIPLES SEDIMENTO, P306.;BRAVARD JP, 1997, COURS DYNAMIQUE SYST.;BRAVARD JP, 1993, HYDROSYSTEMES FLUVIA, V5, P83.;BRICE J, 1973, 4 ANN GEOMORPHOLOGY, P178.;DE MARSILY G, 1998, HYDROGEOL J, V6, P115, DOI 10.1007/S100400050138.;DEMARSILY G, 1993, HYDROGEOLOGIE, V4, P259.;FAYERS FJ, 1992, MATH MODELING WATER, V2, P3.;FERBER J, 1995, SYSTEMES MULTIAGENTS.;HERVOUET JM, 1994, J HYDRAUL RES, V32, P45.;HOWARD AD, 1984, WATER RESOUR RES, V20, P1659, DOI 10.1029/WR020I011P01659.;KOLTERMANN CE, 1996, WATER RESOUR RES, V32, P2617, DOI 10.1029/96WR00025.;KOLTERMANN CE, 1992, SCIENCE, V256, P1775, DOI 10.1126/SCIENCE.256.5065.1775.;MIALL A. D., 1992, FACIES MODELS RESPON, V7, P119.;PERRIER E, 1995, ETUDES PHENOMENES SP, P215.;PERRIER E, 1997, TENDANCES NOUVELLES, P233.;REINECK HE, 1980, DEPOSITIONAL SEDIMEN, P257.;SCHUMM SA, 1987, EXPT FLUVIAL GEOMORP, P129.;SUN T, 1996, WATER RESOUR RES, V32, P2937, DOI 10.1029/96WR00998.;TETZLAFF DM, 1989, SIMULATING CLASTIC S.;TREUIL J. P, 1997, TENDANCES NOUVELLES, P425.;TREUIL JP, 1997, INTELLIGENCE ARTIFIC, P211.;WEBB EK, 1996, WATER RESOUR RES, V32, P533, DOI 10.1029/95WR03399.;WEN XH, 1998, J CONTAM HYDROL, V30, P129, DOI 10.1016/S0169-7722(97)00035-1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Before extracting Metatags, we need to see what kind os separator is used. We check over the cited references [CR] column:\n",
    "message(M$CR[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71 rows and 32 columns\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we may extract the Field Tags (metatags) and import them as new columns, stating the separator just obtained:\n",
    "M <- metaTagExtraction(M, Field = \"CR_AU\", sep = \";\")   # First author of each cited reference\n",
    "M <- metaTagExtraction(M, Field = \"CR_SO\", sep = \";\")   # Source of each cited reference\n",
    "M <- metaTagExtraction(M, Field = \"AU_CO\", sep = \";\")   # Country of affiliation for each co-author\n",
    "M <- metaTagExtraction(M, Field = \"AU1_CO\", sep = \";\")  # Country of affiliation for the first author\n",
    "M <- metaTagExtraction(M, Field = \"AU_UN\", sep = \";\")   # University of affiliation  for each co-author and the corresponding author\n",
    "M <- metaTagExtraction(M, Field = \"SR\", sep = \";\")      # Short tag of the document\n",
    "message(nrow(M), ' rows and ', ncol(M), ' columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Export to Python.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally we create a .csv file for further cleaning on the \"Python-Notebook Bibliometrix\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "write.csv(M,'db_r_to_py.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import from Python.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We read back either the cleaned (from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#M <- read.csv(file = \"db_py_to_r.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "M <- read.csv(file = \"Merged DB (GW-ABM,SH,PM,TC,EM).csv\")\n",
    "M$DE<- as.character(M$DE)\n",
    "M$SO<- as.character(M$SO)\n",
    "M$AU_UN<- as.character(M$AU_UN)\n",
    "M$AU_CO<- as.character(M$AU_CO)\n",
    "M$AU<- as.character(M$AU)\n",
    "M$AU1_CO<- as.character(M$AU1_CO)\n",
    "M$AU_UN<- as.character(M$AU_UN)\n",
    "M$AU_UN_NR<- as.logical(M$AU_UN_NR)\n",
    "M$AU1_UN<- as.character(M$AU1_UN)\n",
    "M$CR_AU<- as.character(M$CR_AU)\n",
    "M$CR_SO<- as.character(M$CR_SO)\n",
    "M$DT<- as.character(M$DT)\n",
    "M$DT2<- as.character(M$DT2)\n",
    "M$ID<- as.character(M$ID)\n",
    "M$JI<- as.character(M$JI)\n",
    "M$LA<- as.character(M$LA)\n",
    "M$PN<- as.character(M$PN)\n",
    "M$PP<- as.character(M$PP)\n",
    "#M$PU<- as.character(M$PU)\n",
    "M$PY<- as.numeric(M$PY)\n",
    "M$RP<- as.character(M$RP)\n",
    "M$SN<- as.character(M$SN)\n",
    "M$AB<- as.character(M$AB)\n",
    "M$DB<- as.character(M$DB)\n",
    "M$CR<- as.character(M$CR)\n",
    "M$SR<- as.character(M$SR)\n",
    "M$AR<- as.character(M$AR)\n",
    "M$C1<- as.character(M$C1)\n",
    "M$DI<- as.character(M$DI)\n",
    "M$SR_FULL<- as.character(M$SR_FULL)\n",
    "M$TC<- as.numeric(M$TC)\n",
    "M$TI<- as.character(M$TI)\n",
    "M$VL<- as.character(M$VL)\n",
    "\n",
    "#M$FU<- as.character(M$FU)\n",
    "#M$BN<- as.character(M$BN)\n",
    "message('Database has ', nrow(M), ' rows and ', ncol(M), ' columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# **Outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Main Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The variable \"results\" saves the bibliographic summary (here \"k\" indicates how many rows will be printed in each table)\n",
    "results <- biblioAnalysis(M, sep = \";\")     \n",
    "options(width=100)\n",
    "S <- summary(object = results, k = 20, pause = FALSE)\n",
    "plot(x = results, k = 40, pause = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sankey Plots**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interactively visualize the main items of three fields and how they are related. The larger flows (arrow widths) can be easily visualized. The width is proportional to the quantity represented. Advantages: highlight main flows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here \"n\" indicates the number of items to plot in each field, and width and height are in pixels\n",
    "threeFieldsPlot(M, fields = c(\"SO\", \"DE\", \"AU1_CO\"), n = c(641, 3989, 4682), width = 1000, height = 900)   # Authors - Author Keywords - Sources (Journal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## **Networks** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Co-occurrences of Author Keywords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NetMatrix <- biblioNetwork(M, analysis = \"co-occurrences\", network = \"author_keywords\", sep = \";\")\n",
    "net <- networkPlot(NetMatrix, Title=\"Author Keywords Co-occurrences\",\n",
    "                   normalize=\"association\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=TRUE,                #methods\n",
    "                   noloops=TRUE, remove.multiple=FALSE, remove.isolates = TRUE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=TRUE, label.color=FALSE, label.n = 150,                            #labels\n",
    "                   n = 4000, size=10, size.cex=TRUE,                                                                   #vertes/nodes \n",
    "                   edgesize=10, edges.min=1, curved = 0)                                                              #edges\n",
    "net2VOSviewer(net, vos.path=\"Temporal Outputs/Co-occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Co-Citation of Authors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NetMatrix <- biblioNetwork(M, analysis = \"co-citation\", network = \"authors\", sep = \";\")\n",
    "net <- networkPlot( NetMatrix, Title=\"Authors Co-Citation Network\",\n",
    "                   normalize=\"association\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=TRUE,                #methods\n",
    "                   noloops=TRUE, remove.multiple=TRUE, remove.isolates = TRUE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=FALSE, label.color=FALSE, label.n = 300,                            #labels\n",
    "                   n=300, size=10, size.cex=TRUE,                                                                       #vertes/nodes \n",
    "                   edgesize=1, edges.min=0.5, curved = 0)\n",
    "net2VOSviewer(net, vos.path=\"Temporal Outputs/Co-citations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Bibliographic Coupling of Authors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NetMatrix <- biblioNetwork(M, analysis = \"coupling\", network = \"authors\",sep = \";\", shortlabel = FALSE)\n",
    "net <- networkPlot( NetMatrix, Title=\"Authors' Coupling\",\n",
    "                   normalize=\"association\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=TRUE,                #methods\n",
    "                   noloops=TRUE, remove.multiple=TRUE, remove.isolates = TRUE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=FALSE, label.color=FALSE, label.n = 800,                            #labels\n",
    "                   n=800, size=10, size.cex=TRUE,                                                                       #vertes/nodes \n",
    "                   edgesize=1, edges.min=0.5, curved = 0)\n",
    "net2VOSviewer(net, vos.path=\"Temporal Outputs/Bibliographic Coupling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Collaboration of Countries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one uses AU_CO metatag\n",
    "NetMatrix <- biblioNetwork(M, analysis = \"collaboration\",  network = \"countries\", sep = \";\")\n",
    "net <- networkPlot( NetMatrix, Title=\"Country collaboration\",\n",
    "                   normalize=\"association\", type=\"auto\", cluster=\"none\", degree=NULL, weighted=TRUE,                #methods\n",
    "                   noloops=TRUE, remove.multiple=TRUE, remove.isolates = TRUE, alpha=0.5, halo=TRUE,                   #other options\n",
    "                   label=TRUE, labelsize=1, label.cex=FALSE, label.color=FALSE,                            #labels\n",
    "                    n = 30, size=10, size.cex=TRUE,                                                   #vertes/nodes \n",
    "                   edgesize=1, edges.min=0.5, curved = 0)                                                              #edges\n",
    "net2VOSviewer(net, vos.path=\"Temporal Outputs/Collaborations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Networks Statistics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we print the available structural properties of the network, and a short summary (showing \"k\" rows)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netstat <- networkStat(NetMatrix, stat = \"all\", type = \"authority\")\n",
    "names(netstat$network)\n",
    "summary(netstat,k=100)\n",
    "# Type: \"degree\", \"closeness\", \"betweenness\",\"eigenvector\",\"pagerank\",\"hub\",\"authority\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Mining**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here we extract terms from textual fields of a manuscript (abstract, title, author’s keywords, keywords plus). Specifically, we start with Titles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scientometrics <- termExtraction(M, Field = \"TI\", stemming = FALSE,language = \"english\", remove.numbers = TRUE, \n",
    "               remove.terms = NULL,keep.terms = NULL, synonyms = NULL, verbose = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we see the terms extracted from the first 10 titles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scientometrics$TI_TM[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we extract terms from abstracts and show the terms extracted from the first abstract**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scientometrics <- termExtraction(M, Field = \"AB\", stemming = FALSE,language = \"english\", remove.numbers = TRUE, \n",
    "               remove.terms = NULL,keep.terms = NULL, synonyms = NULL, verbose = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scientometrics$AB_TM[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Co-Word Analysis: The conceptual structure of a field**  \n",
    "<div style=\"text-align: justify\"> Co-Word analysis uses the most important words or keywords of documents to study the conceptual structure of a research field (It is the only method that uses the actual content of the documents to construct a similarity measure).  \n",
    "It produces semantic maps of a field. Conceptual structure is often used to understand the topics covered by scholars (so-called research front) and identify what are the most important and the most recent issue.\n",
    "Here we map the conceptual structure by using the word co-occurrences in a bibliographic collection. It performs Correspondence Analysis (CA) or Multiple Correspondence Analysis (MCA) to draw a conceptual structure of the field and K-means clustering to identify clusters of documents which express common concepts. </div>  \n",
    "Outputs include:  \n",
    "\n",
    "- Conceptual Structure Map\n",
    "- Topic Dendogram\n",
    "- Factorial maps of the documents with the highest contributes and \n",
    "- factorial map of the most cited documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conceptual Structure Function**  \n",
    "\n",
    "| Function Parameter |   Possibilities   |    Definition    |\n",
    "|:--------------------:|:-------------------:|:------------------:|\n",
    "|*1- Methods*|\n",
    "|   **Field**    | \"ID\", \"DE\", \"ID_TM\", \"DE_TM\", \"TI\" or \"AB\"| Terms extracted from Keywords plus, author's keywords, keywords plus stemmed through Porter's algorithm, Author keywords stemmed through Porter's algorithm, terms extracted from titles and terms extracted from abstracts respectively|\n",
    "|     **method**       | \"CA\", \"MCA\" or \"MDS\"       | Indicates the factorial method used to create the factorial map: Correspondence Analysis, Multiple CA or Metric Multidimensional Scaling (default is MCA)|\n",
    "|     **clust**          | \"auto\" or integer (2-8)     |Indicates the number of clusters to map |\n",
    "|     **k.max**          | *integer* (max 20) | Indicates maximum number of cluster to keep (default is 5)|\n",
    "|     **steeming**          | \"TRUE\" or \"FALSE\"         | If TRUE, Porter's Stemming algorithm is applied to all extracted terms (default is false)|\n",
    "|     **mindegree**          |  *integer*      |indicates the minimum occurrences of terms to analize and plot (default is 2)|\n",
    "|     **labelsize**          | *integer*   | Indicates the label size in the plot (default is 10)|\n",
    "|     **graph**          |  \"TRUE\" or \"FALSE\"        | If TRUE the function plots the maps otherwise they are saved in the output object (Default is true)|\n",
    "|     **documents**          | *integer*      |Indicates the number of documents to plot in the factorial map, used for CA and MCA (default is 10).|\n",
    "|*2- only for CA and MCA*|\n",
    "|     **quali.supp**    | vector    |Vector indicating the indexes of the categorical supplementary variables, used only for CA and MCA |\n",
    "|     **quanti.supp**          | vector   | Vector indicating the indexes of the quantitative supplementary variables, used only for CA and MCA |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using CA method over Keywords Plus\n",
    "CS <- conceptualStructure(M, field=\"DE\", method=\"MCA\", clust=\"3\", k.max = 10, stemming=FALSE, minDegree=10, labelsize=10, documents=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Thematic Evolution Analysis**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Co-word analysis draws clusters of keywords. They are considered as themes, whose density and centrality can be used in classifying themes and mapping in a two-dimensional diagram. Thematic map is a very intuitive plot and we can analyze themes according to the quadrant in which they are placed: (1) upper-right quadrant: motor-themes; (2) lower-right quadrant: basic themes; (3) lower-left quadrant: emerging or disappearing themes; (4) upper-left quadrant: very specialized/niche themes.  \n",
    "The Thematic Map funciton creates a thematic map based on co-word network analysis and clustering. The methodology is inspired by the proposal of Cobo et al. (2011)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First we generate Thematic Maps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res <- thematicMap(M, field = \"DE\", n = 2000, minfreq = 3, stemming = FALSE, size = 0.4, n.labels=3, repel = TRUE)\n",
    "plot(res$map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second we produce a Thematic Evolution Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = c(2005,2018)\n",
    "nexus <- thematicEvolution(M, field = \"DE\", years=years, n = 10, minFreq = 7, size = 0.5, stemming = FALSE, n.labels = 1, repel = TRUE)\n",
    "plot(nexus$map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the Thematic Maps we can finally produce the Thematic Evolution Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TE <- plotThematicEvolution(nexus$Nodes, nexus$Edges, measure = \"inclusion\", min.flow = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reference Publication Year Spectroscopy**  \n",
    "rpys computes a Reference Publication Year Spectroscopy for detecting the Historical Roots of Research Fields. The method was introduced by Marx et al., 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = c(2000,2018)\n",
    "res <- rpys(M, sep = \";\", timespan = years, graph = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Historical Direct Citation Network**  \n",
    "The historiographic map (proposed by E. Garfield) represents a chronological networkmap of most relevant direct citations resulting from a bibliographic collection. We first create the historical citation network, and then we plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histResults <- histNetwork(M, min.citations = 10, sep = \";\", verbose=FALSE)\n",
    "net <- histPlot(histResults, n=50, size = 5, labelsize=7, verbose=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
